{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will take the cadherome interactome data and generate the output require to combine with the mouse lysine acylation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import collections\n",
    "\n",
    "from bioservices import UniProt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import CGAT.IOTools as IOTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_base = \"../raw/\"\n",
    "results_dir = \"./results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "orthologs_inf = os.path.join(raw_base, 'Homo_sapiens-Mus_musculus.txt')\n",
    "mmUni2Ens_inf = os.path.join(raw_base, 'MOUSE_10090_idmapping_selected.tab.gz')\n",
    "hgUni2Ens_inf = os.path.join(raw_base, 'HUMAN_9606_idmapping_selected.tab.gz')\n",
    "\n",
    "high_confidence_cadherin_interactome = os.path.join(raw_base, 'Cadherin_adhesome.csv')\n",
    "\n",
    "ecadherin_glass_inf = os.path.join(raw_base, 'ECadherin_interactome_glass.csv')\n",
    "ecadherin_biotin_inf = os.path.join(raw_base, 'ECadherin_interactome.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we generate the required dictionaries to map human ensembl ids to mouse uniprot ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ENSP00000319690', 'ENSP00000365370'}\n",
      "5242\n",
      "81545\n",
      "28098\n",
      "157433\n"
     ]
    }
   ],
   "source": [
    "mouse2humanEnsPro = collections.defaultdict(set)\n",
    "human2mouseEnsPro = collections.defaultdict(set)\n",
    "\n",
    "\n",
    "with IOTools.openFile(orthologs_inf, 'r') as inf:\n",
    "    for line in inf:\n",
    "        line = line.strip().split('\\t')\n",
    "        if line[5] == 'ortholog':\n",
    "            \n",
    "            if line[1] == 'Homo sapiens':\n",
    "                human_id = line[0]\n",
    "                mouse_id = line[2]\n",
    "\n",
    "            elif line[1] == 'Mus musculus':\n",
    "                human_id = line[2]\n",
    "                mouse_id = line[0]\n",
    "\n",
    "            else:\n",
    "                raise ValueError(line)\n",
    "\n",
    "            mouse2humanEnsPro[mouse_id].add(human_id)\n",
    "            human2mouseEnsPro[human_id].add(mouse_id)\n",
    "\n",
    "# some mouse IDs map to multiple human IDs. In many cases these will both map to the same uniprot ID\n",
    "# so this is not an issue. We can track this following conversion\n",
    "print(mouse2humanEnsPro['ENSMUSP00000107237'])\n",
    "\n",
    "\n",
    "mouseUni2Ens = {}\n",
    "mouseEns2Uni = collections.defaultdict(set)\n",
    "no_id = 0\n",
    "yes_id = 0\n",
    "with IOTools.openFile(mmUni2Ens_inf, 'r') as inf:\n",
    "    for line in inf:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        uni_id = line[0]\n",
    "        try:\n",
    "            yes_id += 1\n",
    "            ens_ids = line[20].split('; ')\n",
    "            mouseUni2Ens[uni_id] = ens_ids\n",
    "            for ens_id in ens_id:\n",
    "                mouseUni2Ens[ens_id] = uni_id\n",
    "        except:\n",
    "            no_id += 1\n",
    "\n",
    "print(no_id)\n",
    "print(yes_id)\n",
    "\n",
    "humanUni2Ens = {}\n",
    "humanEns2Uni = collections.defaultdict(set)\n",
    "no_id = 0\n",
    "yes_id = 0\n",
    "with IOTools.openFile(hgUni2Ens_inf, 'r') as inf:\n",
    "    for line in inf:\n",
    "        line = line.strip().split(\"\\t\")\n",
    "        uni_id = line[0]\n",
    "        try:\n",
    "            yes_id += 1\n",
    "            ens_ids = line[20].split('; ')\n",
    "            humanUni2Ens[uni_id] = ens_ids\n",
    "            for ens_id in ens_ids:\n",
    "                humanEns2Uni[ens_id].add(uni_id)\n",
    "        except:\n",
    "            no_id += 1\n",
    "\n",
    "print(no_id)\n",
    "print(yes_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "----P52480----\n",
      "\n",
      "ENSMUSP00000034834\n",
      "{'ENSP00000320171'}\n",
      "ENSP00000320171\n",
      "{'P14618'}\n",
      "\n",
      "\n",
      "----P47915 (Mouse RL29) ----\n",
      "\n",
      "ENSMUSP00000080203\n",
      "ENSMUSP00000096592\n",
      "ENSMUSP00000117834\n",
      "\n",
      "\n",
      "----P47914 (Human RL29)----\n",
      "\n",
      "ENSP00000294189\n",
      "ENSP00000418868\n",
      "ENSP00000417048\n",
      "ENSP00000418153\n",
      "ENSP00000418346\n",
      "ENSP00000420673\n"
     ]
    }
   ],
   "source": [
    "# This is working all OK for PKM - succesffuly converted from mouse to human ensembl and checked via human uniprot\n",
    "\n",
    "# P52480 = mouse PKM\n",
    "# P14618 = human PKM\n",
    "print(\"\\n\\n----P52480----\\n\")\n",
    "for ens_id in mouseUni2Ens['P52480']:\n",
    "    if len(mouse2humanEnsPro[ens_id]) > 0:\n",
    "        print(ens_id)\n",
    "        print(mouse2humanEnsPro[ens_id])\n",
    "    for human_ens in mouse2humanEnsPro[ens_id]:\n",
    "        print(human_ens)\n",
    "        print(humanEns2Uni[human_ens])\n",
    "\n",
    "print(\"\\n\\n----P47915 (Mouse RL29) ----\\n\")\n",
    "for ens_id in mouseUni2Ens['P47915']:\n",
    "    print(ens_id)\n",
    "    if len(mouse2humanEnsPro[ens_id]) > 0:\n",
    "        print(ens_id)\n",
    "        print(mouse2humanEnsPro[ens_id])\n",
    "    for human_ens in mouse2humanEnsPro[ens_id]:\n",
    "        print(human_ens)\n",
    "        print(humanEns2Uni[human_ens])\n",
    "        \n",
    "        \n",
    "print(\"\\n\\n----P47914 (Human RL29)----\\n\")\n",
    "for ens_id in humanUni2Ens['P47914']:\n",
    "    print(ens_id)\n",
    "    if len(human2mouseEnsPro[ens_id]) > 0:\n",
    "        print(ens_id)\n",
    "        print(human2mouseEnsPro[ens_id])\n",
    "    for mouse_ens in human2mouseEnsPro[ens_id]:\n",
    "        print(mouse_ens)\n",
    "        print(mosueEns2Uni[mouse_ens])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK so there are some orthologs which aren't covered so we will lose some data this way, typically conversion issues!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ConvertMouseUniprot2HumanUniprot(mm_proteins, mouseUni2Ens, mouse2humanEnsPro, humanEns2Uni, one2one=True):\n",
    "    mmUni2Ens_matched, mm2hgUni_matched, hgEns2Uni_matched, proteins_matched  = (0, 0, 0, 0)\n",
    "    \n",
    "    new_mm_proteins = []\n",
    "    new_hg_proteins = []\n",
    "    for protein in mm_proteins:\n",
    "        matches = set()\n",
    "        try:\n",
    "            ens_ids = mouseUni2Ens[protein]\n",
    "            if len(ens_ids) > 0 :\n",
    "                mmUni2Ens_matched +=1 \n",
    "                for ens_id in ens_ids:\n",
    "                    human_ens = mouse2humanEnsPro[ens_id]\n",
    "\n",
    "                    if len(human_ens) > 0:\n",
    "                        mm2hgUni_matched += 1\n",
    "\n",
    "                        for human_en in human_ens:\n",
    "                            humanUnis = humanEns2Uni[human_en]\n",
    "                            #print(human_en)\n",
    "                            #print(humanUnis)\n",
    "\n",
    "                            if len(humanUnis) > 0:\n",
    "                                hgEns2Uni_matched += 1\n",
    "                                matches.update(humanUnis)\n",
    "                                #print(matches)\n",
    "                    else:\n",
    "                        #print(ens_ids)\n",
    "                        #print(ens_id)\n",
    "                        #print(human_ens)\n",
    "                        #break\n",
    "                        pass\n",
    "\n",
    "                if len(matches) > 0:\n",
    "                    if one2one and len(matches) > 1:\n",
    "                        continue\n",
    "                    proteins_matched += 1\n",
    "                    for match in matches:\n",
    "                        new_hg_proteins.append(match)\n",
    "                        new_mm_proteins.append(protein)\n",
    "            \n",
    "        except KeyError:\n",
    "            pass\n",
    "            #print('protein not found in uniprot mapping file: ', protein)\n",
    "\n",
    "    print(len(mm_proteins), mmUni2Ens_matched, mm2hgUni_matched, hgEns2Uni_matched, proteins_matched)\n",
    "    \n",
    "    return new_mm_proteins, new_hg_proteins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 0 0 0\n",
      "([], [])\n"
     ]
    }
   ],
   "source": [
    "print(ConvertMouseUniprot2HumanUniprot(['P47915'], mouseUni2Ens, mouse2humanEnsPro, humanEns2Uni))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 1 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['P52480'], ['P14618'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ConvertMouseUniprot2HumanUniprot(['P52480'], mouseUni2Ens, mouse2humanEnsPro, humanEns2Uni, one2one=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a convertion function we need to provide a sensible list of mouse ids to convert. We'll use the full swiss-prot collection as a startpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = UniProt()\n",
    "\n",
    "u_results = u.search(\"organism:10090+and+reviewed:yes\", columns=\"id,entry name\", limit=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  uniprot_id         name\n",
      "0     Q02248  CTNB1_MOUSE\n",
      "1     Q62226    SHH_MOUSE\n",
      "2     Q01705  NOTC1_MOUSE\n",
      "3     P22725  WNT5A_MOUSE\n",
      "4     P10417   BCL2_MOUSE\n",
      "(16853, 2)\n"
     ]
    }
   ],
   "source": [
    "uniprot_ids_df = pd.DataFrame.from_records(\n",
    "        [x.split() for x in u_results.strip().split(\"\\n\")[1:]],\n",
    "        columns=[\"uniprot_id\", \"name\"])\n",
    "\n",
    "print(uniprot_ids_df.head())\n",
    "print(uniprot_ids_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16853 16673 13101 13330 12317\n",
      "12317\n",
      "12165\n",
      "12233\n",
      "12081\n"
     ]
    }
   ],
   "source": [
    "mm_proteins, hg_proteins = ConvertMouseUniprot2HumanUniprot(\n",
    "    uniprot_ids_df['uniprot_id'].tolist(),\n",
    "    mouseUni2Ens, mouse2humanEnsPro, humanEns2Uni, one2one=True)\n",
    "\n",
    "# need to remove instances where the same hg protein is apparently a one-2-one ortholog of multiple mouse proteins\n",
    "# this occurs because we previous;y only checked for 1-2-1 in mouse->human direction\n",
    "\n",
    "mm2hg = {x:y for x, y in zip(mm_proteins, hg_proteins)}\n",
    "hg2mm = {y:x for x, y in zip(mm_proteins, hg_proteins)}\n",
    "\n",
    "print(len(mm2hg))\n",
    "print(len(hg2mm))\n",
    "\n",
    "for hg_protein, count in collections.Counter(hg_proteins).most_common():\n",
    "    if count > 1:\n",
    "        mm2hg.pop(hg2mm[hg_protein])\n",
    "        hg2mm.pop(hg_protein)\n",
    "    else:\n",
    "        # using most_common so break as soon as we've reached the '1s'\n",
    "        break\n",
    "        \n",
    "print(len(mm2hg))\n",
    "print(len(hg2mm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so we have 16853 mouse uniprot ids converted to 12317 human uniprot ids via a mouse2human ensembl id map. The major step at which we lost proteins is the conversion from mouse to human ensembl protein ids (16673 --> 13101 = 78.6%). This is fine since this is the 1:1 ortholog conversion. The other steps resulted in only modest loss of ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173, 11)\n",
      "130\n"
     ]
    }
   ],
   "source": [
    "cadherin_adhesome_df = pd.read_table(high_confidence_cadherin_interactome, sep=\"\\t\")\n",
    "\n",
    "\n",
    "mm_uniprot_ids = []\n",
    "\n",
    "for protein in cadherin_adhesome_df['UniProt ID']:\n",
    "    protein = protein.replace(\" \", \"\")\n",
    "    if protein in hg2mm:\n",
    "        mm_uniprot_ids.append(hg2mm[protein])\n",
    "    else:\n",
    "        mm_uniprot_ids.append(np.nan)\n",
    "\n",
    "cadherin_adhesome_df['Mouse_uniprot_IDs'] = mm_uniprot_ids\n",
    "\n",
    "print(cadherin_adhesome_df.shape)\n",
    "print(sum(cadherin_adhesome_df['Mouse_uniprot_IDs'].notnull()))\n",
    "\n",
    "cadherin_adhesome_df[['Mouse_uniprot_IDs']].to_csv(\n",
    "    os.path.join(results_dir, \"cadherine_proteins.tsv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parseECadherinInfile(infile, abundance_column=None):\n",
    "    assert abundance_column is not None\n",
    "    ecadherin_df = pd.read_table(infile, sep='\\t')\n",
    "\n",
    "    mm_uniprot_ids = []\n",
    "    for protein_ids in ecadherin_df['Protein IDs']:\n",
    "        matches = set()\n",
    "        for protein in protein_ids.split(';'):\n",
    "            if protein in hg2mm:\n",
    "                matches.add(hg2mm[protein])\n",
    "        if len(matches) <1:\n",
    "            mm_uniprot_ids.append(np.nan)\n",
    "        else:\n",
    "            mm_uniprot_ids.append(';'.join(matches))\n",
    "\n",
    "    ecadherin_df['Mouse_uniprot_IDs'] = mm_uniprot_ids\n",
    "\n",
    "    ecadherin_df[\"rank\"] = ecadherin_df[abundance_column].rank()\n",
    "    ecadherin_df.rename(columns={abundance_column: \"interactome_abundance\",\n",
    "                                 \"Protein IDs\": \"Human_uniprot_IDs\"},\n",
    "                        inplace=True)\n",
    "\n",
    "    ecadherin_df =  ecadherin_df[\n",
    "        ['Mouse_uniprot_IDs', \"Human_uniprot_IDs\", \"interactome_abundance\", \"rank\"]]\n",
    "    #ecadherin_df[]\n",
    "    return ecadherin_df\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({1: 1841, 2: 105, 3: 20, 4: 8, 7: 3, 6: 2, 5: 1})\n",
      "Counter({1: 511, 2: 36, 3: 11, 4: 1, 6: 1, 7: 1})\n",
      "  Mouse_uniprot_IDs                                  Human_uniprot_IDs  \\\n",
      "0            P10126                        P68104;Q5VTE0;Q5JR01;A6PW80   \n",
      "1            P68372                                             P68371   \n",
      "2            P68373  F5H5D3;Q9BQE3;F8VVB9;F8VQQ4;F8VS66;F8VRZ4;F8VW...   \n",
      "3            Q9D8N0                               P26641;B4DTG2;E7EMT2   \n",
      "4            P62827          B5MDF5;P62826;J3KQE5;F5H018;H0YFC6;B4DV51   \n",
      "\n",
      "   interactome_abundance    rank  \n",
      "0               6.333808  1980.0  \n",
      "1               2.546583  1979.0  \n",
      "2               2.252746  1978.0  \n",
      "3               1.795667  1977.0  \n",
      "4               1.763019  1975.5  \n"
     ]
    }
   ],
   "source": [
    "ecadherin_glass_df = parseECadherinInfile(ecadherin_glass_inf, '%iBAQ')\n",
    "ecadherin_biotin_df = parseECadherinInfile(ecadherin_biotin_inf, '(iBAQ ALL/iBAQ ALL sum)*100 (%)')\n",
    "print(collections.Counter([len(str(x).split(\";\")) for x in ecadherin_glass_df['Mouse_uniprot_IDs']]))\n",
    "print(collections.Counter([len(str(x).split(\";\")) for x in ecadherin_biotin_df['Mouse_uniprot_IDs']]))\n",
    "\n",
    "print(ecadherin_glass_df.head())\n",
    "ecadherin_glass_df.to_csv(os.path.join(results_dir, \"ecadherin_glass.tsv\"), index=False)\n",
    "ecadherin_biotin_df.to_csv(os.path.join(results_dir, \"ecadherin_biotin.tsv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
